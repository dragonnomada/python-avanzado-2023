# Módulo 106 - Concurrencia y Paralelismo

## Concucurrencia

La **concurrencia** permite ejecutar tareas simultáneas con acceso a la misma memoria del programa principal, completando soluciones de diversas formas:

* **Mediante hilos** - Cada hilo completa una solución en un segundo plano.
* **Mediante valores futuros** - Cada valor futuro marca una solución que será completada con el paso del tiempo, y podemos registrar un `callback` que notifique cuándo el valor futuro ya está disponible.
* **Mediante ejecutores** - Cada ejecutor lanza tareas en hilos que completan soluciones en segundo plano (hilos auto-administrados).
* **Mediante funciones asíncronas** - Cada función asíncrona completa una solución en segundo plano y se espera hasta que sea resuelta.

### Hilos (`threading | class Thread`)

Los hilos son útiles cuándo hay una única tarea que debe ser resuelta en un hilo, es decir, si una tarea demora demasiado y su resultado debe ser envuelto y procesado en segundo plano, mientras el programa hace otras cosas, usaremos los hilos.

> `[n1.py]` **Hilo funcional (rudimentario)** - `threading.Thread(target=task, args=(123))`

```py
def task(id):
    print(f"Task started: {id}")
    from time import sleep
    print(f"Task {id} waiting...")
    sleep(5)
    print(f"Task {id} completed")
    return id ** 2

if __name__ == "__main__":
    import threading

    # 1. Definir el hilo (con la función objetivo)
    t = threading.Thread(target=task, args=(123,)) # single-tuple (value,) | single-value (value)

    print("Initializing threads...")
    # 2. Inicializar el hilo
    t.start()

    print("Waiting threads...")

    # 3. Sincronización o espera del hilo hasta su completado
    t.join()

    print("Threads has been finished")
```

> `[n2.py]` **Hilo funcional (Generalizado)** - `threading.Thread(target=task, args=(123))`

```py
def task(id):
    print(f"Task started: {id}")
    from time import sleep
    print(f"Task {id} waiting...")
    sleep(5)
    print(f"Task {id} completed")
    return id ** 2

if __name__ == "__main__":
    import threading

    inputs = [123, 456, 789, 111, 222, 333]
    
    print("inputs:", inputs)

    # 1. Definición de los hilos
    threads = [ threading.Thread(target=task, args=(id,)) for id in inputs ]

    # 2. Inicialización de los hilos
    [ t.start() for t in threads ]

    # 3. Sincronización o espera de los hilos
    outputs = [ t.join() for t in threads ]

    print("outputs:", outputs)
```

**IMPORTANTE:** Cuándo se ejecutan más hilos que procesadores (`CPUs`) disponibles por la máquina, se alcanza un problema de bloqueo y los hilos podrían fallar o morir (ser aniquilados por Python). El módulo `threading` no soporta automáticamente la limitación de los hilos y nos vemos forzados a usar otros módulos como `concurrent.futures.ThreadPoolExecutor` para solucionar estre problema y sólo ejecutar cierta cantidad hilos al mismo tiempo sin superar el límite de los procesadores.

> `[n3.py]` **Hilo orientados a objetos** - `threading.Thread`

```py
import threading

def task(id):
    print(f"Task started: {id}")
    from time import sleep
    print(f"Task {id} waiting...")
    sleep(5)
    print(f"Task {id} completed")
    return id ** 2

class MyTaskInThread(threading.Thread):

    id = None
    output = None

    def __init__(self, id):
        super().__init__() # La herencia en Python nos obliga a inicializar la clase base
                           # Para que `self` esté disponible (sino podría causar error)
        self.id = id

    def run(self):
        # code here ... or ... code in other place
        self.output = task(self.id)
    
if __name__ == "__main__":
    print("Defining threads...")

    # 1. Definición de los hilos (Orientada a Objetos)
    t1 = MyTaskInTread(123)
    t2 = MyTaskInTread(456)
    t3 = MyTaskInTread(789)
    t4 = MyTaskInTread(111)
    t5 = MyTaskInTread(222)
    t6 = MyTaskInTread(333)

    print("Starting threads...")

    # 2. Inicialización o lanzamiento de los hilos
    t1.start()
    t2.start()
    t3.start()
    t4.start()
    t5.start()
    t6.start()

    print("Waiting threads...")

    # 3. Sincronización o espera de los hilos
    t1.join()
    t2.join()
    t3.join()
    t4.join()
    t5.join()
    t6.join()

    print("Threads is already finish")

    print(t1.output)
    print(t2.output)
    print(t3.output)
    print(t4.output)
    print(t5.output)
    print(t6.output)
```

> `[n4.py]` **Hilo orientados a objetos (Generalizado)** - `threading.Thread`

```py
import threading

def task(id):
    print(f"Task started: {id}")
    from time import sleep
    print(f"Task {id} waiting...")
    sleep(5)
    print(f"Task {id} completed")
    return id ** 2

class MyTaskInThread(threading.Thread):

    id = None
    output = None

    def __init__(self, id):
        super().__init__() # La herencia en Python nos obliga a inicializar la clase base
                           # Para que `self` esté disponible (sino podría causar error)
        self.id = id

    def run(self):
        # code here ... or ... code in other place
        self.output = task(self.id)
    
if __name__ == "__main__":
    print("Defining threads...")

    inputs = [123, 456, 789, 111, 222, 333]

    print("inputs:", inputs)

    # 1. Definición de los hilos (Orientada a Objetos)
    threads = [ MyTaskInThread(id) for id in inputs ]

    print("Starting threads...")

    # 2. Inicialización o lanzamiento de los hilos
    [ t.start() for t in threads ]

    print("Waiting threads...")

    # 3. Sincronización o espera de los hilos
    [ t.join() for t in threads ]

    print("Threads is already finish")

    outputs = [ t.output for t in threads ]

    print("outputs:", outputs)
```

### Valores Futuros (`Future`)

Los valores a futuro son útiles, cuándo hay muchas tareas y nos interesa retener el resultado de dichas tareas, hasta que se completen. Por ejemplo, en una aplicación de TKinter (Tool-Kit interface for Python), se crean aplicaciones con botones y demás, y podríamos usar valores a futuro para ejecutar tareas sencillas (de resultado simple), los cuales se ejecuten entre múltiples partes del código, sin necesariamente estar hilos.

> `n5.py` **Hilos con Valores Futuros** - `concurrent.futures.Future`

```py
from concurrent.futures import Future

def task(id):
    print(f"Task started: {id}")
    from time import sleep
    print(f"Task {id} waiting...")
    sleep(5)
    print(f"Task {id} completed")
    return id ** 2

def task_in_future(id, callback):
    output_future = Future()

    output_future.add_done_callback(callback)

    def in_thread():
        output = task(id)
        output_future.set_result(output)

    import threading

    threading.Thread(target=in_thread).start()

if __name__ == "__main__":
    task_in_future(123, lambda future: print("Task 1:", future.result()))
    task_in_future(456, lambda future: print("Task 2:", future.result()))
    task_in_future(789, lambda future: print("Task 3:", future.result()))
    task_in_future(111, lambda future: print("Task 4:", future.result()))
    task_in_future(222, lambda future: print("Task 5:", future.result()))
    task_in_future(333, lambda future: print("Task 6:", future.result()))
```

> `n6.py` **Hilos con Valores Futuros (Generalizado)** - `concurrent.futures.Future`

```py
from concurrent.futures import Future

def task(id):
    print(f"Task started: {id}")
    from time import sleep
    print(f"Task {id} waiting...")
    sleep(5)
    print(f"Task {id} completed")
    return id ** 2

def task_in_future(id, callback):
    output_future = Future()

    output_future.add_done_callback(callback)

    def in_thread():
        output = task(id)
        output_future.set_result(output)

    import threading

    threading.Thread(target=in_thread).start()

if __name__ == "__main__":
    futures_and_ids = []

    inputs = [123, 456, 789, 111, 222, 333]

    [ task_in_future(id, lambda future: futures_and_ids.append((id, future))) for id in inputs ]

    # PROBLEMA: La lista de futures_and_ids no se va a llenar hasta que los callbacks sean llamados

    futures = [ future for id, future in futures_and_ids ]
    
    from concurrent.futures import wait

    wait(futures)

    from concurrent.futures import as_completed

    outputs = as_completed(futures)

    ids = [ id for id, future in futures_and_ids ]

    print(list(zip(ids, outputs)))
```

### Funciones asíncronas (`async-def | await | coroutime | asyncio`)

### Executors (`ThreadPoolExecutor`)

Los executors son útiles cuándo una tarea debe ser propagada con múltiples entradas, y dicha tarea se requiere ejecutar automáticamente en hilos limitados.

> `n7.py` **El executor por piscina de hilos** - (`ThreadPoolExecutor`)

```py
from concurrent.futures import ThreadPoolExecutor

def task(id):
    print(f"Task started: {id}")
    from time import sleep
    print(f"Task {id} waiting...")
    sleep(5)
    print(f"Task {id} completed")
    return id ** 2

if __name__ == "__main__":
    executor1 = ThreadPoolExecutor(max_workers=4) # Máximo de hilos

    future1 = executor1.submit(task, 123)
    future2 = executor1.submit(task, 456)
    future3 = executor1.submit(task, 789)
    future4 = executor1.submit(task, 111)
    future5 = executor1.submit(task, 222)
    future6 = executor1.submit(task, 333)

    from concurrent.futures import wait
    wait([future1, future2, future3, future4, future5, future6])

    # from concurrent.futures import as_completed
    # outputs = as_completed([future1, future2, future3, future4, future5, future6])

    outputs = [ future.result() for future in [future1, future2, future3, future4, future5, future6] ]

    print(outputs)
```

> `n8.py` **El executor por piscina de hilos generalizado** (`ThreadPoolExecutor`)

```py
from concurrent.futures import ThreadPoolExecutor

def task(id):
    print(f"Task started: {id}")
    from time import sleep
    print(f"Task {id} waiting...")
    sleep(5)
    print(f"Task {id} completed")
    return id ** 2

if __name__ == "__main__":
    executor1 = ThreadPoolExecutor(max_workers=4) # Máximo de hilos

    inputs = [123, 456, 789, 111, 222, 333]

    futures = [ executor1.submit(task, id) for id in inputs ] 

    from concurrent.futures import wait
    wait(futures)

    outputs = [ future.result() for future in futures ]

    print(outputs)
```

### Funciones asíncronas (`async-await`)

Las funciones asíncronas son útiles cuándo hay demasiadas funcionalidades que esperan datos y están seriadas, es decir, cuándo tenemos que obtener resultados y esperar por ellos, y dichos resultados usarlos en otras funciones que también esperen sus propios resultados, entonces, podemos usar funciones asíncronas que se esperen entre ellas, para formar una línea lógica de **espera-petición**, cuyo resultado será retenido de manera lineal, para ser utilizado en la próxima línea de código.

> `n9.py` **Función asíncrona** (`async def <- await`)

```py
async def task_part1(id):
    # await axios.get(...)
    # await sockeio.once(...)
    import requests
    response = requests.get(f"https://randomuser.me/api?seed={id}")
    data = response.json()
    results = data["results"]
    user = results[0]
    return user

async def task_part2(user):
    pictureURL = user["picture"]["large"]
    import requests
    response = requests.get(pictureURL)
    content = response.content
    return content

async def task_part3(filename, content):
    with open(filename, "wb") as file:
        file.write(content)

async def task_async(id):
    user = await task_part1(id)
    picture_content = await task_part2(user)
    await task_part3(f"output/{id}.png", picture_content)

def main():
    import asyncio

    loop1 = asyncio.get_event_loop()

    loop1.run_until_complete(task_async(123))
    loop1.run_until_complete(task_async(456))
    loop1.run_until_complete(task_async(789))

if __name__ == "__main__":
    main()
```

## Paralelismo

El **paralelismo** permite ejecutar *mútiples procesos* simultáneos con su propia memoria (programas completos), que generen soluciones independientes, que puedan ser sincronizadas desde un lugar superior.

* **Mediante el `Process`** - La clase `multiprocessing.Process` define un mecanismo para alcanzar una solución (completar una tarea), en un proceso independiente, es decir, un progra que será replicado para cada entrada.
* **Mediante el `Pool` de procesos** - Los procesos pueden ser tratados como un mapeo de funciones que deben ejecutarse con sus propios recursos y devolver los resultados para cada proceso.
* **Mediante el `ProcessPoolExecutor`** - Los procesos pueden ser propagados de manera similar a los hilos (`ThreadPoolExecutor`), pero tomando en cuanta que no serán hilos, sino procesos en sí mismos (programas independientes).

### Procesos (`multiprocessing | class Process`)

Los procesos son útiles cuándo tenemos una única función que queremos que se comporte como un hilo, pero bajo un proceso (programa) independiente.

> `n10.py` **El proceso definido (rudimentario)** - (`class multiprocessing.Process`)

```py
import multiprocessing

# threading -> process
class DownloadUserPictureProcess (multiprocessing.Process):

    id = None

    def __init__(self, id):
        super().__init__()

        self.id = id # Inicializamos la propiedad `self.id` 
                     # con el parámetro de construcción `id`

    def run(self):
        import requests
        response_user = requests.get(f"https://randomuser.me/api?seed={self.id}")
        data = response_user.json()
        results = data["results"]
        user = results[0]
        pictureURL = user["picture"]["large"]
        response_picture = requests.get(pictureURL)
        picture_content = response_picture.content
        with open(f"output/{self.id}.png", "wb") as file:
            file.write(picture_content)

if __name__ == "__main__":
    process1 = DownloadUserPictureProcess(123)
    process2 = DownloadUserPictureProcess(456)
    process3 = DownloadUserPictureProcess(789)
    process4 = DownloadUserPictureProcess(111)
    process5 = DownloadUserPictureProcess(222) # Error (se superó el número de núcleos)
    process6 = DownloadUserPictureProcess(333) # Error (se superó el número de núcleos)

    process1.start()
    process2.start()
    process3.start()
    process4.start()
    process5.start()
    process6.start()
```

### `Pool`

Los `Pool` son útiles cuándo queremos controlar de manera correcta los procesos que se están ejecutando.

```py
from multiprocessing import Pool

def download_user_picture(id):
    import requests
    response_user = requests.get(f"https://randomuser.me/api?seed={id}")
    data = response_user.json()
    results = data["results"]
    user = results[0]
    pictureURL = user["picture"]["large"]
    response_picture = requests.get(pictureURL)
    picture_content = response_picture.content
    filename = f"output/{id}.png"
    with open(filename, "wb") as file:
        file.write(picture_content)
    return filename

if __name__ == "__main__":
    pool1 = Pool(processes=4)

    inputs = [123, 456, 789, 111, 222, 333]

    outputs = pool1.map(download_user_picture, inputs)

    print(outputs)
```

### `ProcessPoolExecutor`

Los `ProcessPoolExecutor` son útiles cuándo tenemos que ejecutar múltiples tareas en procesos automáticos y auto-administrados que se comporten de manera similar a los `ThreadPoolExecutor` (se genera la interfaz: hazlo en un hilo o hazlo en un proceso).

```py
from concurrent.futures import ProcessPoolExecutor

def download_user_picture(id):
    import requests
    response_user = requests.get(f"https://randomuser.me/api?seed={id}")
    data = response_user.json()
    results = data["results"]
    user = results[0]
    pictureURL = user["picture"]["large"]
    response_picture = requests.get(pictureURL)
    picture_content = response_picture.content
    filename = f"output/{id}.png"
    with open(filename, "wb") as file:
        file.write(picture_content)
    return filename

if __name__ == "__main__":
    executor1 = ProcessPoolExecutor(max_workers=4)

    inputs = [123, 456, 789, 111, 222, 333]

    # Peticiones bajo demanda (on-demand | hot-spot)
    futures = [ executor1.submit(download_user_picture, id) for id in inputs ]

    from concurrent.futures import wait

    wait(futures)

    outputs = [ future.result() for future in futures ]

    print(outputs)
```